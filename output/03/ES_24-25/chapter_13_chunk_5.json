{
  "chapter_no": 13,
  "subchapter_no": 5,
  "content": "Chapter 13 Summary:\nSummary generation failed with 400: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '[\\n  {\\n    \"name\": \"ChapterSummary\",\\n    \"parameters\": {\\n      \"summary\": \"The rapid advancement of artificial intelligence (AI) presents both opportunities and challenges for labor markets worldwide. Historical parallels with earlier technological revolutions reveal the critical role of inclusive institutions in managing disruption and ensuring equitable outcomes. India\\'s demographic advantage and diverse economic landscape position it uniquely to benefit from AI, but achieving these benefits requires significant investments in education and workforce skilling. \\n\\nThe chapter discusses the potential impact of AI on labor markets, citing estimates that nearly 75 million jobs globally are at risk of automation due to AI. The International Labour Organisation estimates that 75 million jobs may be displaced, while the International Monetary Fund warns that AI poses risks of job displacements, particularly for emerging markets and developing economies. \\n\\nIn India, an IIM Ahmedabad survey highlights that 68% of surveyed employees expect their jobs to be partially or fully automated by AI within the next five years. The NASSCOM estimates that the Indian AI market will grow at 25-35% CAGR by 2027. \\n\\nThe chapter emphasizes the need for robust institutions to ensure that the gains from technology translate into inclusive growth. Enabling institutions focus on equipping the workforce with necessary skills, while insuring institutions provide a safety net for workers. Stewarding institutions are necessary to design an approach that balances public welfare without stifling innovation. \\n\\nThe chapter also discusses the challenges of scaling up AI adoption, including reliability, resource efficiency, and infrastructure deficits. It highlights that AI\\'s experimental nature makes its real-world utility unclear, and that the industry\\'s focus on increasing AI adoption may not be sufficient to validate the technology. \\n\\nThe resource challenge is critical, with training AI models becoming increasingly expensive and data centers consuming large amounts of electricity and water. The chapter concludes that India\\'s services-driven economy offers opportunities for enhancing productivity, and that education and skilling are critical to driving success. \\n\\nThe chapter also estimates demand elasticities for India\\'s services sectors, finding that sectors like financial services, health and social work, and business services have high elasticities, indicating potential for employment growth. The chapter argues that labor-augmenting technology can increase productivity and employment, and that India\\'s workforce must be equipped with future-ready skills to capitalize on emerging technologies.\"\\n    }\\n  }\\n]'}}\n\nSubchapter 5 Content:\n# Vision to Viability: AI's Real World Challenges\n\n## VISION TO VIABILITY: AI'S REAL WORLD CHALLENGES\n\n## Differentiating between Breakthrough and Practicality\n\n13.25  A  breakthrough  in  the  context  of  technology  refers  to  a  significant  discovery that overcomes a major barrier, enabling new possibilities or dramatically advancing the state of the art. It is also characterized by its ability to solve previously unsolvable problems, introduce novel capabilities, or revolutionise existing systems, processes, or industries. This is the stage at which Artificial Intelligence finds itself right now. Large Language Models are capable of acing exams and achieving high test scores, but the field is still far from having a model come up with original, publishable research.\n\n13.26  Conversely,  practicality  refers  to  feasibility,  effectiveness,  and  usefulness  in addressing real-world problems or needs. This also encompasses ease of implementation, cost-effectiveness, scalability, user access, and the ability to deliver clearly measurable benefits.  Achieving  this  stage  is  the  most  challenging  part  since  many  innovations\n\nthat emerged over the years have been clear breakthroughs but failed to find the mass acceptance that comes to characterise a General Purpose Technology. AI today has the potential to deliver clearly measurable benefits in terms of productivity, but the costs, especially in terms of investment required is high.\n\n13.27 At its current stage of development, AI is more experimental as it is still finding its footing.  This  is  not  inherently  negative,  as  it  signifies  innovation's  curious  and  exploratory nature. However, from a practical standpoint, its experimental nature makes its realworld  utility  unclear  despite  the  technology  demonstrating  impressive  capabilities. For instance,  the  pursuit  of  smarter  AI  models  promises  to  propel  the  applicability of self-driving cars but identifying why they are needed, their cost-effectiveness, and social acceptability remains an ongoing challenge. Similarly, chatbots can convincingly simulate human conversation but their practical effectiveness in customer service is not established since customers prefer having their complex questions dealt with by humans 30 .\n\n13.28  The  industry  has  placed  its  chips  on  increasing  AI  adoption,  hoping  that  if the  technology  reaches  as  broad  an  audience  as  possible,  users  will,  on  their  own, eventually come up with more applications, thus validating the technology. For now, while AI is useful in exploring and optimising certain jobs, particularly ones that are knowledge-based or creative, the full scope of its practicality is still limited due to the degree of human intervention necessary in order to extract useful outputs. AI models, particularly  overly  complex  generative  AI  which  are  too  rich  and  have  too  many parameters are unconcerned with the truth, unconcerned with the 'correctness' of its output and unconcerned with the realities of the world. It is known to 'hallucinate' and generate outputs that are not based on what is true but rather on what is the best fit for question 31 . Utilising AI to the best of its abilities right now requires one to be fully aware of its limitations.\n\n## Reliability\n\n13.29  In most day-to-day use cases involving personal use, even an error rate of 10 per cent would not have any significant impact since the user would most likely identify the error and correct it. The stakes are much higher when it comes to deploying AI in business and real-world applications as the severity of the consequences will vary from one application to another. A customer service chatbot might have many chances to correct misunderstandings, whereas a path planning algorithm for an autonomous vehicle gets only one chance to get it right. Ignoring the reliability problem and hasty implementation results in severe, unintended consequences.\n\n30  Cogito Customer Experience Survey Results. 6th August 2024, https://tinyurl.com/ynf37mm6\n\n31    Hicks, M. T., Humphries, J., &amp; Slater, J. (2024). ChatGPT is bullshit. Ethics and Information Technology, 26(2), 38, https://tinyurl.com/3cun5e9d\n\n13.30  Several  examples  noted  in  a  publication  by  McKendrick  and  Thurai  (2022) demonstrate the non-negotiable nature of reliability 32 . A self-driving car fatally struck a  pedestrian  on  a  four-lane  road  because  it  failed  to  recognize  the  individual  as  a pedestrian, as the person was not near a crosswalk, which was the typical circumstance represented in its training data. Application of AI in recruitment turned out to prefer male candidates over female applicants due to the larger number of males in its training sample. The company attempted several times to make the AI screener gender-neutral but failed. Predictive Policing using AI also tends to have a bias against minorities 33 .\n\n13.31 Time-tested  liability  frameworks  applicable  to  commercial  products  may  not apply in a straightforward manner to AI products as solving the reliability problem is  also  necessary  to  mitigate  risks  from  AI  applications 34 .  Additionally,  given  the nuanced relationship between humans and accountability, individuals tend to feel less responsible as their direct involvement in actions decreases. This phenomenon becomes particularly significant when artificial intelligence is used to replace human decisionmaking within firms and organizations. The introduction of AI further distances humans from  the  ethical  responsibilities  traditionally  tied  to  decision-making,  potentially exacerbating a lack of accountability. In such frameworks, where firms increasingly rely on AI as a substitute for human judgment, the importance of ensuring AI's reliability becomes paramount. This is because, unlike humans, AI lacks the inherent capacity for accountability, making the ethical and operational implications of its use even more critical to address.\n\n13.32  Arvind  Narayanan  and  Sayash  Kapoor  of  Princeton  note  that  LLMs  are  'not reliable  enough  to  be  successful  products'  -  yet 35 .  They  state  that  for  AI  to  achieve mass adoption, companies need to start approaching AI development like Software development. The product needs to be reliable and dependable. Until such a time, the labour displacement effects of AI may not be widespread since human oversight will be a must for any kind of AI application.\n\n## The Infrastructure Challenge\n\n13.33  The third criterion for the diffusion of new technology is growth in supporting infrastructure. As illustrated by Carlota Perez in her book investigating the history of technological revolutions 36 , the necessary infrastructure is crucial for the proliferation\n\n32    McKendrick, J., &amp; Thurai, A. (2022). AI isn't ready to make unsupervised decisions. Harvard Business Review, 15, 10, https://tinyurl.com/4uxf3bbz\n\n33    Predictive Policing Algorithms are racist. Will Douglas Heaven. MIT Technology Review. July 2020, https:// tinyurl.com/yaef2evv\n\n34  Rahul Matthan (Trilegal), Unpublished Manuscript, December 2024.\n\n35  AI Agents that Matter. Sayash Kapoor and Arvind Narayanan. 3rd July 2024, https://tinyurl.com/3pd7ftkk\n\n36    Perez, C. (2002). Technological revolutions and financial capital: The dynamics of bubbles and golden ages. In Technological revolutions and financial capital. Edward Elgar Publishing.\n\nof new technology as it provides the externalities that facilitate adoption and widespread use. The infrastructure is installed in the initial phase when the excitement over the potential of the new technology runs high, creating the conditions for the full deployment of the technology in the coming decades.\n\n13.34  Canals, waterways, and turnpike roads provided the connectivity required for the industrial revolution, facilitating the movement of inputs and finished goods. The age of the automobile gained momentum due to the construction of roads and highways all across the United States. The expansion of the electricity grid provided households access to power, thus fuelling the demand for home appliances and leading to the era of  mass  production.  The  proliferation  of  computers  and  infrastructure  created  for telecommunications gave impetus to the adoption of the Internet.\n\n13.35  Once a  technology  had  proven  its  practicality  (more  than  its  reliability,  as  reliability would  be  fine-tuned  with  subsequent  iterations  of  the  technology),  infrastructure creation naturally followed. However, since building infrastructure is a highly timeconsuming process, the full potential of the technology could not be harnessed till the support infrastructure was widely available. The development of AI, and the rate of adoption is similarly going to depend on the availability of quality infrastructure and the pace of its creation.\n\n13.36  Infrastructure,  in  the  case  of  AI,  is  not  as  straightforward  as  in  previous technological revolutions since its requirements transcend the physical realm. Apart from the already-known aspects such as land, reliable chip supply, and data centres, chief  among  AI  infrastructure  is  data,  which  is  the  lifeblood  of  AI  development. Training AI models cannot be done on raw data, as previously discussed; data is highly prone to bias the model. Additionally, data in its raw form can include instances of toxicity, vulgar content, and other dimensions that can lead to the model performing unexpectedly. More often than not, prior to data making its way into the training set for a model, it is extensively cleaned by humans who filter the dataset for any and all of the issues mentioned above. Cleaning introduces its own set of biases as data can be included or excluded at the discretion of the developers, biasing the overall output of the model.\n\n13.37 For  AI  to  be  widely  adopted  across  industries,  a  holistic  infrastructure  that combines technological resources, human expertise, and organisational readiness is needed. Changes of this magnitude take time to materialise, and even longer to reach the point where the new technology seamlessly synergises with the entire value-addition process. Thus, concerns over AI displacing labour may be somewhat ameliorated by the time it takes for complementary facilities needed for AI adoption at scale, to emerge.\n\n## The Resource Challenge\n\n13.38  The most critical obstacle to the large-scale proliferation of AI in the medium term is resource efficiency. For AI to scale effectively, technological advancements and performance gains must be coupled with significant reductions in costs and more efficient utilisation of scarce resources-an achievement that remains elusive. The challenge is compounded by the fact that modern AI systems, still in their developmental infancy, demand enormous investment in research and development. Moreover, the prevailing trajectory in AI development prioritises performance over cost-effectiveness, driven by a belief that any compromise on model performance in favour of cost savings would lead to subpar outcomes. This approach, while understandable, underscores the urgency of addressing the pressing need for sustainable and efficient AI innovations.\n\n13.39  Training AI models are becoming increasingly expensive as the availability of data is saturating and high-quality data acquisition costs are rising. Training the first 'Transformer' model developed by Google, which laid the foundation for ChatGPT, cost around USD 930 dollars. In stark contrast, training OpenAI's GPT-4 cost the company USD 78.4 million, while the costs incurred by Google for training Gemini Ultra stood at USD 191.4 million 37 . As costs are only expected to go up, developers have been exploring the idea of using 'Synthetic Data', but this is rife with its own set of challenges. Artificially generated data come with data distribution bias, are characterised by completeness which influences the model's resilience, can contain many inaccuracies and errors, can neglect temporal and dynamic aspects found in real data and are highly inconsistent when evaluated on factors present in real data 38 . Utilising synthetic data to augment previous training data leads to the model's learning essentially coming to a halt and repeated use of synthetic data leads to 'model collapse'.\n\n13.40  Secondly, developing more sophisticated models comes with significant costs as well. Since processing user queries utilises vast computational resources, AI firms incur running costs for the model. For instance, in the case of OpenAI's o3 model mentioned earlier, the breakthrough in processing capability came at a very high cost. In running the ARC-AGI benchmark, which is considered one of the most challenging tasks for an AI to undertake, OpenAI incurred a cost of USD 200,000 39  for its low-efficiency model. While the firm asked the author not to disclose its high-efficiency cost, the author does state  that  the  amount  to  compute  was  172  times  the  low-efficiency  model's  figure. Running increasingly complex models is computationally tasking, exerting hardware, energy and other resource demands.\n\n37  Visualizing the Training Costs of AI Models Over Time. Visual Capitalist, https://tinyurl.com/bderacpn\n\n38    Hao, S., Han, W., Jiang, T., Li, Y., Wu, H., Zhong, C., ... &amp; Tang, H. (2024). Synthetic data in AI: Challenges, applications, and ethical implications. arXiv preprint arXiv:2401.01629, https://tinyurl.com/zkau6cn4\n\n39    OpenAI o3 breakthrough high score on ARC-AGI-PUB. Francois Chollet. 20th December 2024, https://tinyurl. com/2xy69wu8\n\n13.41 In this regard, AI's energy requirements are no mystery. Globally, all data centres already consume more electricity than countries such as Italy, Taiwan, Australia, Spain and  Malaysia  among  others 40 .  These  requirements  will  only  increase  with  greater adoption.  A  recently  published  Bloomberg  analysis  estimated  that  powering  Data Centres for AI around the world is expected to reach up to 1580 terawatt-hours, which is as much electricity as India consumes 41 . Hardware also needs cooling, which is reliant on water, much of it drinking quality. Cooling is estimated to need over a billion litres of water per day. Further, Data Centre campuses are built on a vast amount of land, and finding the right piece of land that fulfils the power and water requirements is going to drive up land prices in resource-rich areas. The chips powering AI are reliant on a steady supply of minerals such as silicone, gold, silver, aluminium, tin, and other rare earth minerals. The magnitude of scarce resources required for AI proliferation would not be much of a concern if there were no competing needs driving demand for the same resources. However, this is not the case and scaling up AI has the potential to start a bidding war for minerals, land, and water, driving up prices for essential resources.\n\n13.42  Without  ground-breaking  innovations  and  strategies  to  make  AI  scaling economically viable-both financially and in terms of resource consumption-efforts to democratise AI will jeopardise critical global priorities such as energy security, water security, and even housing or food security. The construction of sprawling data centres risks displacing essential land use, further exacerbating these challenges. The imperative for AI developers is clear: scaling down resource consumption while simultaneously boosting performance is not just a technical hurdle but the defining bottleneck that will shape the future of AI. The time to address this pressing issue is now.\n\n13.43  Technological revolutions that achieved mass adoption only did so because, over the  course  of  time,  they  got  the  delicate  mix  of  the  factors  outlined  in  the  previous sections right. Practicality, reliability, infrastructure and efficiency need to all work in tandem before true large scale adoption happens. No amount of investment can force mass adoption unless the technology makes economic sense for the user and for the society. In the case of AI, if it makes sense for the former and not the latter, policymakers have to step in and take some hard decisions.",
  "tags": [
    "AI_Adoption_Challenges",
    "Technological_Practicality",
    "Resource_Efficiency"
  ]
}