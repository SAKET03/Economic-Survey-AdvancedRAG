{
  "chapter_no": 13,
  "subchapter_no": 6,
  "content": "Chapter 13 Summary:\nSummary generation failed with 400: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '[\\n  {\\n    \"name\": \"ChapterSummary\",\\n    \"parameters\": {\\n      \"summary\": \"The rapid advancement of artificial intelligence (AI) presents both opportunities and challenges for labor markets worldwide. Historical parallels with earlier technological revolutions reveal the critical role of inclusive institutions in managing disruption and ensuring equitable outcomes. India\\'s demographic advantage and diverse economic landscape position it uniquely to benefit from AI, but achieving these benefits requires significant investments in education and workforce skilling. \\n\\nThe chapter discusses the potential impact of AI on labor markets, citing estimates that nearly 75 million jobs globally are at risk of automation due to AI. The International Labour Organisation estimates that 75 million jobs may be displaced, while the International Monetary Fund warns that AI poses risks of job displacements, particularly for emerging markets and developing economies. \\n\\nIn India, an IIM Ahmedabad survey highlights that 68% of surveyed employees expect their jobs to be partially or fully automated by AI within the next five years. The NASSCOM estimates that the Indian AI market will grow at 25-35% CAGR by 2027. \\n\\nThe chapter emphasizes the need for robust institutions to ensure that the gains from technology translate into inclusive growth. Enabling institutions focus on equipping the workforce with necessary skills, while insuring institutions provide a safety net for workers. Stewarding institutions are necessary to design an approach that balances public welfare without stifling innovation. \\n\\nThe chapter also discusses the challenges of scaling up AI adoption, including reliability, resource efficiency, and infrastructure deficits. It highlights that AI\\'s experimental nature makes its real-world utility unclear, and that the industry\\'s focus on increasing AI adoption may not be sufficient to validate the technology. \\n\\nThe resource challenge is critical, with training AI models becoming increasingly expensive and data centers consuming large amounts of electricity and water. The chapter concludes that India\\'s services-driven economy offers opportunities for enhancing productivity, and that education and skilling are critical to driving success. \\n\\nThe chapter also estimates demand elasticities for India\\'s services sectors, finding that sectors like financial services, health and social work, and business services have high elasticities, indicating potential for employment growth. The chapter argues that labor-augmenting technology can increase productivity and employment, and that India\\'s workforce must be equipped with future-ready skills to capitalize on emerging technologies.\"\\n    }\\n  }\\n]'}}\n\nSubchapter 6 Content:\n# AI and India: Are There Opportunities?\n\n## AI AND INDIA: ARE THERE OPPORTUNITIES?\n\n13.44  As India contemplates the integration of AI into its economy, the lessons of past technological revolutions underscore the critical importance of proactive institutional response. The time afforded now must be well utilised to minimise the adverse effects\n\n40    AI  is  already  wreaking  havoc  on  Global  Power  Systems.  Bloomberg.  21st  June  2024,  https://tinyurl.com/ rdk9p3c9\n\n41  Published in Bloomberg, 13th December 2024, https://tinyurl.com/4c66sa22\n\nto the best of our capabilities involves equipping the workforce with future-ready skill. We must also use this time to put in place mechanisms to cushion societal impacts, a  challenge  that  resonates  deeply  with  India's  unique  demographic  and  economic landscape.\n\n13.45  Looking ahead, the nation's predominantly services-driven economy, coupled with its young and dynamic population, offers a fertile ground for leveraging the benefits of emerging technologies, only if proactively and carefully managed. Technology does not always have to displace labour but instead can be put to use in augmenting the productivity of the workforce. Just as history provides a reason for caution, history also provides a cause for optimism about the effectiveness of strong institutions which can foster an environment where man and machine work together.\n\n13.46  Further, the exposure of medium- to high-skill jobs to AI driven automation may not be as high as certain estimates, due to the inherent limitations of AI as detailed in Box XIII.1. Thus, the labour augmenting potential of AI should also not be ignored.\n\n## Box XIII.1: Demystifying Artificial Intelligence\n\nIn the simplest terms, the 'AI' tools on the market today, particularly Generative AI, are statistical models, utilising significant computing power, that are a function of large amounts of text, images, and other forms of data fed into them. The processing of any input is broken down across many layers for the most complex models, with each layer containing several thousand nodes (or neurons 42 ). This combination of layers and nodes allows the model to 'think', 'reason', and process data at unimaginable scales, generating an output along the parameters the model has been trained for.\n\nWhen you ask any modern chatbot driven by an underlying large language model a simple question  such  as  'Where  does  the  sun  rise  and  set?',  the  model  does  not  interpret  the language in the question as an actual human does. This is because 'AI' has no understanding of the concepts of letters and syllables. The machine processes input text using a series of mathematical computations involving matrices. First, the text is broken into smaller units called tokens in a process known as tokenisation, where each token is mapped to a unique number. For example, the phrase 'AI revolution' might be tokenised to [342, 2591], where these numbers correspond to the indices of the words in the model's vocabulary.\n\nOnce  tokenised,  the  model  uses  mechanisms  to  compute  the  frequency  of  token  pairs, triplets,  and  other  sequences  between  each  word  and  all  other  words  in  the  input.  This allows the model to assign importance (weights) to different words based on their context.\n\n42    In  the  1940s,  Warren McCulloch and Walter Pitts developed a mathematical model to mimic how the brain processes information. They proposed that neurons in the brain function like switches, turning \"on\" or \"off\" based on signals they receive from other neurons. Their model used simple logic, where a neuron activates if the  sum of incoming signals surpasses a certain threshold, similar to binary decision-making in computers. This foundational concept inspired the development of artificial neural networks, computer systems designed to emulate the brain's signal processing for tasks like pattern recognition, decision-making, and problem-solving.\n\nThese weighted representations are passed through layers of the neural network, where patterns and relationships are refined. The network output assigns probability values to each possible token, representing how likely each one will appear next. The tokens with the highest probabilities are selected and mapped back to their corresponding words in the vocabulary, generating a coherent text output. The new tokens generated are then fed back into the model, making it appear that the bot is equipped to have a flowing conversation with the user.\n\nThus, to respond to a user's query, the data analysis performed by the model is essentially a  game  of  'guess  the  next  word'.  In  other  words,  it  is  a  highly  complex  version  of  the autocomplete function we already see on our computers and smartphones. Generative AI are trained to simply predict the next word in a sequence of words by calculating probabilities based on the user input text. Considering the non-linearity and complexity of language, such an exercise is computationally very expensive. To generate a single-line response to the user's question (in our example, 'The sun rises in the east and sets in the west'), the model may need to perform anywhere between 10 to 20 trillion arithmetic operations to generate a 11-word response. Similar principles govern the functioning of other generative AI.\n\nStrides made in AI-research is awe-inspiring and will most likely be helpful in the coming years 43 .  However, Michael Wooldridge from the University of Oxford had suggested that claims of intelligence required more rigorous scrutiny, stating that large language models, despite their dazzling appearance of human-like competence, are not 'AI' 44 . While capable of some superficial logical reasoning and problem-solving, these models are limited in their extended capabilities. Anything additional expected from these models must be explicitly coded into them, which is very different from what is traditionally considered 'intelligent'. To claim that machines are 'learning' is to assign the wrong label since these models use predictive and probabilistic statistics to generate an output.\n\nConsider  an  AI-powered  marketing  tool  that  determines  campaign  success  based  solely on click-through rates and conversions. While efficient, it might ignore brand perception, customer loyalty, and the long-term impact of the campaign on the business. In education, implementing  an  AI-based  grading  system  for  students  that  evaluates  essays  based  on grammar, structure, and word count can be quick and efficient. But the AI may miss the value brought by creativity, originality, and critical thinking expressed in the content.\n\nAlong similar lines, AI in healthcare can recommend treatments that prioritise statistical outcomes  since  it  cannot  factor  parameters  such  as  quality  of  life,  patient  preferences, and  ethical  considerations.  Relying  on  AI  for  judicial  decisions  also  involves  risks  since predicting recidivism or determining bail requires balancing subjective considerations such as fairness, individual circumstances, and social impact. Judgements passed in courts are much more than simple prediction tasks and are a product of personal experience combined with domain-specific knowledge, the former of which AI lacks.\n\n43    However,  the  efficiency  of  the  models  is  still  a  research  question  that  remains  unanswered  thus  far  in  the Generative AI community. Larger models drive up the demand for more computational resources and energy, which in turn drives up the cost of running these models.\n\n44  ChatGPT is not 'true AI'. Michael Wooldridge, 2023,  https://tinyurl.com/45s6dkad\n\nAdvancements in computer science may just as well address these concerns in the future. However, in the meantime, just as machines are designed for specific  tasks  rather  than universal application, AI functions as a tool tailored to particular purposes. This means it is  more suited to supplement human action rather than be a total replacement for work performed by them.",
  "tags": [
    "AI_Adoption",
    "Economic_Growth",
    "Workforce_Development"
  ]
}